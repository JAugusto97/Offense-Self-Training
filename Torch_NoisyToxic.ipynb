{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torch_NoisyToxic.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAugusto97/noisystudentNLP/blob/main/Torch_NoisyToxic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://skimai.com/fine-tuning-bert-for-sentiment-analysis/"
      ],
      "metadata": {
        "id": "ihYgOFMzMHZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgCCQCUAuz-Z"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers emoji --quiet"
      ],
      "metadata": {
        "id": "1fdxqOyBcvXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tGwYu4ZCWxfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from scipy.special import expit as sigmoid\n",
        "from transformers import AutoModel, AutoTokenizer, AdamW, get_scheduler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import re\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.propagate = False"
      ],
      "metadata": {
        "id": "ba3IPaucco-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "RMro1WI2cF4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    # pretrained_bert_name = \"vinai/bertweet-base\"\n",
        "    pretrained_bert_name = \"distilbert-base-cased\"\n",
        "    seed = 7\n",
        "    datasets_path = \"drive/MyDrive/NoisyToxic/data/\"\n",
        "    steps = 3\n",
        "    min_confidence = 0.8    \n",
        "    hidden_dim = 128\n",
        "    train_epochs = 1\n",
        "    do_lower_case = False\n",
        "    batch_size = 8\n",
        "    max_seq_len = 32\n",
        "    dropout_proba = 0.1\n",
        "    increase_dropout_step = 0.1\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "    def to_json():\n",
        "        return {\n",
        "            \"pretrained_bert_name\": CFG.pretrained_bert_name,\n",
        "            \"seed\": CFG.seed,\n",
        "            \"datasets_path\": CFG.datasets_path,\n",
        "            \"steps\": CFG.steps,\n",
        "            \"hidden_dim\": CFG.hidden_dim,\n",
        "            \"min_confidence\": CFG.min_confidence,\n",
        "            \"train_epochs\": CFG.train_epochs,\n",
        "            \"do_lower_case\": CFG.do_lower_case,\n",
        "            \"batch_size\": CFG.batch_size,\n",
        "            \"max_seq_len\": CFG.max_seq_len,\n",
        "            \"dropout_proba\": CFG.dropout_proba,\n",
        "            \"increase_dropout_step\": CFG.increase_dropout_step,\n",
        "            \"timestamp\": CFG.timestamp\n",
        "        }"
      ],
      "metadata": {
        "id": "nEbWRFu66LmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plog(text):\n",
        "    print(text)\n",
        "    log.write(text + \"\\n\")\n",
        "\n",
        "def load_olid(datasets_path):\n",
        "    eng_path = os.path.join(datasets_path, \"english\")\n",
        "\n",
        "    train_path = os.path.join(eng_path, \"OLIDv1.0\", \"olid-training-v1.0.tsv\")\n",
        "    test_path = os.path.join(eng_path, \"OLIDv1.0\", \"testset-levela.tsv\")\n",
        "    test_labels_path = os.path.join(eng_path, \"OLIDv1.0\", \"labels-levela.csv\")\n",
        "    unlabeled_path = os.path.join(eng_path, \"unlabeled\", \"tweets_augmented.csv\")\n",
        "\n",
        "    train_df = pd.read_csv(train_path, engine=\"python\", sep='\\t')[[\"tweet\", \"subtask_a\"]]\n",
        "    train_df[\"subtask_a\"] = train_df[\"subtask_a\"].apply(lambda x: 1 if x == \"OFF\" else 0)\n",
        "    train_df = train_df.rename({\"tweet\": \"text\", \"subtask_a\": \"toxic\"}, axis=1)\n",
        "\n",
        "    test_df = pd.read_csv(test_path, engine=\"python\", sep='\\t')\n",
        "    test_labels = pd.read_csv(test_labels_path, header=None)\n",
        "    test_df[\"toxic\"] = test_labels[1].apply(lambda x: 1 if x == \"OFF\" else 0)\n",
        "    test_df = test_df[[\"tweet\", \"toxic\"]]\n",
        "    test_df = test_df.rename({\"tweet\": \"text\"}, axis=1)\n",
        "\n",
        "    unlabeled_df = pd.read_csv(unlabeled_path)[[\"text\", \"text_augmented\"]]\n",
        "    unlabeled_df[\"text\"] = unlabeled_df[\"text\"]\n",
        "    unlabeled_df[\"text_augmented\"] = unlabeled_df[\"text_augmented\"]\n",
        "\n",
        "    plog(\n",
        "        f\"\"\"\n",
        "        Loaded OLID V1.0\n",
        "\n",
        "        Train Size: {len(train_df)}\n",
        "            Positives: {len(train_df[train_df[\"toxic\"] == 1])}\n",
        "            Negatives: {len(train_df[train_df[\"toxic\"] == 0])}\n",
        "        Test Size: {len(test_df)}\n",
        "            Positives: {len(test_df[test_df[\"toxic\"] == 1])}\n",
        "            Negatives: {len(test_df[test_df[\"toxic\"] == 0])}\n",
        "        Augmented Data: {len(unlabeled_df)}\n",
        "\n",
        "        \"\"\"\n",
        "    )\n",
        "    return train_df, test_df, unlabeled_df\n",
        "\n",
        "class OlidDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "class UnlabeledDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, labels):\n",
        "        self.text = df[\"text\"].to_list()\n",
        "        self.labels = labels\n",
        "        self.text_augmented = df[\"text_augmented\"].to_list()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\"text\": self.text[idx], \"labels\": self.labels[idx], \"text_augmented\": self.text_augmented[idx]}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, pretrained_bert_name, hidden_dim, n_classes, dropout_prob=0.1):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, hidden_dim, n_classes\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = AutoModel.from_pretrained(pretrained_bert_name)\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "    \n",
        "        # for param in self.bert.parameters():\n",
        "        #     param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def initialize_model(pretrained_bert_name, hidden_dim, n_labels, dropout_proba, epochs):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    model = BertClassifier(pretrained_bert_name, hidden_dim, n_labels, dropout_proba)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "    return model, optimizer, scheduler\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    epochs,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    val_dataloader=None,\n",
        "    evaluate_during_training=False,\n",
        "    is_student=False,\n",
        "    unlabeled_dataloader=None,\n",
        "):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(input_ids, attention_mask)\n",
        "\n",
        "            if is_student:\n",
        "                unl_batch = next(iter(unlabeled_dataloader))\n",
        "                unl_inputs = batch_tokenize(unl_batch[\"text_augmented\"])\n",
        "\n",
        "                unl_input_ids = torch.LongTensor(unl_inputs['input_ids']).to(device)\n",
        "                unl_attention_mask = torch.LongTensor(unl_inputs['attention_mask']).to(device)\n",
        "                unl_labels = unl_batch[\"labels\"].to(device)\n",
        "\n",
        "                unl_logits = model(unl_input_ids, unl_attention_mask)\n",
        "\n",
        "                loss = loss_fn(logits, labels)\n",
        "                loss = loss + loss_fn(unl_logits, unl_labels)\n",
        "\n",
        "            else:\n",
        "                loss = loss_fn(logits, labels)\n",
        "\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluate_during_training:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids, attention_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "def bert_predict(model, dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in dataloader:\n",
        "        # Load batch to GPU\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids, attention_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "    labels = np.argmax(probs, axis=1)\n",
        "\n",
        "    return probs, labels\n",
        "\n",
        "def batch_tokenize(sents):\n",
        "    tokenized = tokenizer.batch_encode_plus(\n",
        "        sents,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=CFG.max_seq_len\n",
        "    )\n",
        "\n",
        "    return tokenized\n"
      ],
      "metadata": {
        "id": "dQ7d0O3XEvWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = f\"EXP_{CFG.timestamp}.log\"\n",
        "log = open(f\"{os.path.join( fname)}\", \"w\")\n",
        "plog(json.dumps(CFG.to_json(), indent=4))"
      ],
      "metadata": {
        "id": "qzhmWqv0-zJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df, unlabeled_df = load_olid(CFG.datasets_path)"
      ],
      "metadata": {
        "id": "6ax3jcImLNuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    CFG.pretrained_bert_name,\n",
        "    # use_fast=True,\n",
        "    # normalize=True,\n",
        ")"
      ],
      "metadata": {
        "id": "_H0XRkD29qSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = batch_tokenize(train_df[\"text\"].to_list())\n",
        "trainset = OlidDataset(tokenized_train, labels=train_df[\"toxic\"].to_list())\n",
        "\n",
        "tokenized_test = batch_tokenize(test_df[\"text\"].to_list())\n",
        "testset = OlidDataset(tokenized_test, labels=test_df[\"toxic\"].to_list())\n",
        "\n",
        "unlabeledset = UnlabeledDataset(unlabeled_df, labels=[0 for i in range(len(unlabeled_df))])"
      ],
      "metadata": {
        "id": "H_3OJnj394za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(trainset, shuffle=True, batch_size=CFG.batch_size)\n",
        "test_dataloader = DataLoader(testset, batch_size=CFG.batch_size)\n",
        "\n",
        "unl_batch_size = (len(unlabeled_df)//(len(train_df)//CFG.batch_size))\n",
        "unlabeled_dataloader = DataLoader(unlabeledset, shuffle=True, batch_size=unl_batch_size)"
      ],
      "metadata": {
        "id": "tQmVpg75797d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "set_seed(CFG.seed)\n",
        "\n",
        "student_model, student_optimizer, student_scheduler = initialize_model(\n",
        "    pretrained_bert_name = CFG.pretrained_bert_name,\n",
        "    hidden_dim = CFG.hidden_dim,\n",
        "    n_labels = 2,\n",
        "    dropout_proba = CFG.dropout_proba+0.1, \n",
        "    epochs=CFG.train_epochs\n",
        ")\n",
        "\n",
        "teacher_model, teacher_optimizer, teacher_scheduler = initialize_model(\n",
        "    pretrained_bert_name = CFG.pretrained_bert_name,\n",
        "    hidden_dim = CFG.hidden_dim,\n",
        "    n_labels = 2,\n",
        "    dropout_proba = CFG.dropout_proba, \n",
        "    epochs=CFG.train_epochs\n",
        ")\n",
        "\n",
        "# for i in range(CFG.steps):\n",
        "teacher_model.to(device)\n",
        "teacher_model.train()\n",
        "train(\n",
        "    model = teacher_model,\n",
        "    train_dataloader = train_dataloader,\n",
        "    epochs = CFG.train_epochs,\n",
        "    optimizer = teacher_optimizer,\n",
        "    scheduler = teacher_scheduler,\n",
        "    val_dataloader = test_dataloader,\n",
        "    evaluate_during_training=True,\n",
        "    is_student=False,\n",
        ")"
      ],
      "metadata": {
        "id": "VKApH7xRWSAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.eval()\n",
        "probas, preds = bert_predict(teacher_model, test_dataloader)\n",
        "print(classification_report(test_df[\"toxic\"], preds))"
      ],
      "metadata": {
        "id": "0htn4PNYHCm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "labels = []\n",
        "augmented = []\n",
        "for unl_batch in unlabeled_dataloader:\n",
        "    unl_inputs = batch_tokenize(unl_batch[\"text\"])\n",
        "\n",
        "    unl_input_ids = torch.LongTensor(unl_inputs['input_ids']).to(device)\n",
        "    unl_attention_mask = torch.LongTensor(unl_inputs['attention_mask']).to(device)\n",
        "    unl_logits = teacher_model(unl_input_ids, unl_attention_mask)\n",
        "    unl_softmax = F.softmax(unl_logits).cpu().detach().numpy()\n",
        "\n",
        "    high_confidence_positive_idxs = np.where(unl_softmax[:,1] >= CFG.min_confidence)[0] # high confidence positive preds\n",
        "    high_confidence_negative_idxs = np.where(unl_softmax[:,0] >= CFG.min_confidence)[0]\n",
        "    high_confidence_negative_idxs = np.random.choice(high_confidence_negative_idxs, size=len(high_confidence_positive_idxs), replace=False)\n",
        "\n",
        "    high_confidence_idxs = np.append(high_confidence_positive_idxs, high_confidence_negative_idxs)\n",
        "\n",
        "    high_confidence_augmented = list(map(unl_batch[\"text_augmented\"].__getitem__, high_confidence_idxs.tolist()))\n",
        "    high_confidence_text = list(map(unl_batch[\"text\"].__getitem__, high_confidence_idxs.tolist()))\n",
        "    unl_labels = np.argmax(unl_softmax[high_confidence_idxs], axis=1)\n",
        "\n",
        "    texts.extend(high_confidence_text)\n",
        "    labels.extend(unl_labels)\n",
        "    augmented.extend(high_confidence_augmented)\n",
        "\n",
        "df = pd.DataFrame({\"text\": texts, \"text_augmented\": augmented})\n",
        "processed_dataset = UnlabeledDataset(df, labels=labels)\n",
        "\n",
        "unl_batch_size = len(df)//(len(train_df)//CFG.batch_size)\n",
        "if unl_batch_size <= 0:\n",
        "    unl_batch_size = 1\n",
        "\n",
        "augmented_dataloader = DataLoader(processed_dataset, shuffle=True, batch_size=unl_batch_size)"
      ],
      "metadata": {
        "id": "CfXqXZa2U1sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del teacher_model"
      ],
      "metadata": {
        "id": "gauhk9_r_2mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.to(device)\n",
        "student_model.train()\n",
        "train(\n",
        "    model = student_model,\n",
        "    train_dataloader = train_dataloader,\n",
        "    epochs = CFG.train_epochs,\n",
        "    optimizer = student_optimizer,\n",
        "    scheduler = student_scheduler,\n",
        "    val_dataloader = test_dataloader,\n",
        "    evaluate_during_training=True,\n",
        "    is_student=True,\n",
        "    unlabeled_dataloader=augmented_dataloader\n",
        ")"
      ],
      "metadata": {
        "id": "G74Oo10Vf4Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.eval()\n",
        "probas, pred = bert_predict(student_model, test_dataloader)\n",
        "pred"
      ],
      "metadata": {
        "id": "o4rflZG7S_cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_df[\"toxic\"], pred))"
      ],
      "metadata": {
        "id": "G0Ik6cFp-eMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sGaZ7njv-nPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}